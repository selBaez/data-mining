\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{float}
\usepackage{hyperref}


\title{
	{\textbf{Data Mining Techniques} \\ Assignment Proposal}
}
\author{
\footnotesize{Selene Baez Santamaria (2572529)} \\
\footnotesize{Andrea Jemmett (2573223)} \\
\footnotesize{Dimitris Alivanistos (2578740)}
}

\begin{document}

\maketitle

\begin{abstract}
We would like to work with a dataset provided by Kaggle, containing data
produced at the Large Hadron Collider (LHC). The objective of the Kaggle
competition was to discover proof of a phenomenon that scientists still cannot
explain: the charged lepton flavour violation.
\end{abstract}

\section{Flavours of Physics}
In physics some quantities such as momentum or energy are conserved, that is
their values are transformed but never destroyed. In the Standard Model of
particle physics, the current theory that explains interactions at microscopic
scale, the lepton flavour (leptons being a class of subatomic particles, lepton
flavour is the number of electrons and electrons-neutrinos, muon and
muon-neutrinos and tau and tau-neutrino) is a conserved quantity.

In many proposed extensions to the Standard Model though, this property is not
explained, meaning that some decays that do not conserve lepton flavour are
admissible. Observation of this kind of decay would be a clear indication of the
violation of the lepton flavour and could constitute as evidence for this
phenomenon.

\section{The Dataset}
As said, the dataset was offered on Kaggle for a competition organized by
institutions such as CERN and LHCb. The data have been collected directly at the
LHC during experiments with high energy particles collisions. The dataset
consists of a collection of collision events and their properties. The objective
of the Kaggle competition was to predict whether a $\tau \rightarrow 3\mu$ decay
(the one that identifies a lepton flavour) was present in the collision. From
scientists this phenomenon is supposed \emph{not} to happen, so the goal of the
competition was to discover $\tau \rightarrow 3\mu$ happening more frequently
than scientists currently expect.

\subsection{Training Data}
For training there is a labeled dataset ready to be used to train a classifier.
The label, marked as \texttt{signal} with range in ${0,1}$ where 1 identifies
signal events while 0 represents background events). Signal events have been
simulated while background events come from real data collected by the LHCb
detectors, observing collision of accelerated particles with a specific mass
range in which $\tau \rightarrow 3\mu$ can't happen.

The training dataset is given is CSV format and contains 49 features plus target
label. Follows a list of available features for training:
\begin{itemize}
	\item \texttt{FlightDistance} - distance between $\tau$ and PV (primary vertex, the
		original protons collision point);
	\item \texttt{FlightDistanceError} - error on FlightDistance;
	\item \texttt{mass} - reconstructed $\tau$ candidate invariant mass, which
		is \textit{absent in the test samples};
	\item \texttt{LifeTime} - life time of tau candidate;
	\item \texttt{IP} - Impact Parameter of tau candidate;
	\item \texttt{IPSig} - Significance of Impact Parameter;
	\item \texttt{VertexChi2} - $\chi^2$ of $\tau$ vertex;
	\item \texttt{dira} - cosine of the angle between the $\tau$ momentum and line
		between PV and tau vertex;
	\item \texttt{pt} - transverse momentum of $\tau$;
	\item \texttt{DOCAone} - Distance of Closest Approach between p0 and p1;
	\item \texttt{DOCAtwo} - Distance of Closest Approach between p1 and p2;
	\item \texttt{DOCAthree} - Distance of Closest Approach between p0 and p2;
	\item \texttt{IP\_p0p2} - Impact parameter of the p0 and p2 pair;
	\item \texttt{IP\_p1p2} - Impact parameter of the p1 and p2 pair;
	\item \texttt{isolationa} - track isolation variable;
	\item \texttt{isolationb} - track isolation variable;
	\item \texttt{isolationc} - track isolation variable;
	\item \texttt{isolationd} - track isolation variable;
	\item \texttt{isolatione} - track isolation variable;
	\item \texttt{isolationf} - track isolation variable;
	\item \texttt{iso} - track isolation variable;
	\item \texttt{CDF1} - cone isolation variable;
	\item \texttt{CDF2} - cone isolation variable;
	\item \texttt{CDF3} - cone isolation variable;
	\item \dots; % TODO complete the list
	\item \texttt{signal} - is the target variable to predict.
\end{itemize}

\subsection{Testing}
For this Kaggle competition the submission procedure is different from the usual
ones. The dataset comes with, besides a test set, an \textit{agreement} and a
\textit{correlation} set. Any submission has to pass the agreement and
correlation checks before being scored on the test set.

\subsubsection{Agreement Test}
\label{sec:agreement}
The agreement dataset contains real and simulated events for a much more known,
observed and understood decay: $Ds \rightarrow \varphi\pi$. The motivation for
this check is that since the training set contains simulated data (for a
phenomenon not well understood), it is possible for the classifier to reach high
performances by picking up features that are not well modeled by the simulation.
The check then requires the classifier not to expose a large discrepancy when
applied to real-world and simulated data.

For this score, we are provided with a dataset on the control channel $Ds
\rightarrow \varphi\pi$ which has the same features as the training set. This
type of decay is not present in the training data. The
\textit{Kolmogorov-Smirnov} test is used to evaluate the differences between
real and simulated data between the classifier distribution on each sample.
The Kolmogorov-Smirnov metric has to be smaller than 0.09 to pass the agreement
check.

\subsubsection{Correlation Test}
\label{sec:correlation}
This test checks whether the classifier is uncorrelated with the $\tau$ mass.
Because mass is a measured quantity, scientists don't trust it when building a
model. Correlation with mass in an artificial signal-like peak or lead to
incorrect estimations of background signals.

The \texttt{mass} column is not included in the test dataset. However, this hidden
mass information is used to perform a \textit{Cramer-von Mises} test,
iteratively comparing two distributions of a) predicted values from submission
for entire dataset and b) predicted values within a certain mass region in
rolling window fashion along the whole mass range. Getting similar distributions
for all mass sub-regions means that the classifier is not correlated with the
mass. The submission must give a Cramer-von Mises value less than 0.002 to pass
the correlation test.

\subsubsection{Test Set}
\label{sec:test-set}
The test set has the same columns that the training set has except for
\texttt{mass}, \texttt{production}, \texttt{min\_ANNmuon} and \texttt{signal}.
The data contained in this dataset consists of:
\begin{enumerate}
	\item simulated signal events for $\tau \rightarrow 3\mu$;
	\item real background events for $\tau \rightarrow 3\mu$;
	\item simulated events for the $Ds \rightarrow \varphi\pi$;
	\item real background events for $Ds \rightarrow \varphi\pi$.
\end{enumerate}
Events related to the control channel are not used for scoring, but by the
agreement check (Section \ref{sec:agreement}). One should treat all samples as
coming from the same collision channel during classification.

\section{Discussion}


\end{document}

